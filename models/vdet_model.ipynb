{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I0KTHhFJ1zU"
      },
      "source": [
        "# **Instructions:**\n",
        "* Update the paths (datasets, any existing checkpoints, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb410THxWcJ_",
        "outputId": "2b457a0c-664c-4da3-d62b-f6a889ec19bf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install sklearn\n",
        "!pip install to_pandas\n",
        "!pip install numpy\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzGfGKPCt-3S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "#from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3Qb5K8rP0Lg"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv(\"/content/train.csv\")\n",
        "val_dataset = pd.read_csv(\"/content/val.csv\")\n",
        "\n",
        "# string to arrays\n",
        "from ast import literal_eval\n",
        "train_dataset['one-hot'] = train_dataset['one-hot'].apply(literal_eval)\n",
        "val_dataset['one-hot'] = val_dataset['one-hot'].apply(literal_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMyrEnbIvnZ3"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 12\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"CAUKiel/JavaBERT\") \n",
        "\n",
        "class vulnerabilityClassifier(nn.Module):\n",
        "    DROPOUT_PROB = 0.1 # default value\n",
        "    N_CLASSES = 22 \n",
        "\n",
        "    def __init__(self):\n",
        "        super(vulnerabilityClassifier, self).__init__()\n",
        "        self.model = transformers.AutoModel.from_pretrained(\"CAUKiel/JavaBERT\", output_hidden_states=True) \n",
        "        self.dropout = nn.Dropout(self.DROPOUT_PROB) \n",
        "        self.linear = nn.Linear(768 * 4, self.N_CLASSES) # If you are using last four hidden state\n",
        "        # self.linear = nn.Linear(768, self.N_CLASSES) # If you are using the pooler output\n",
        "        self.step_scheduler_after = \"batch\"\n",
        "\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        \"\"\"Use last four hidden states\"\"\"\n",
        "        all_hidden_states = torch.stack(self.model(ids, attention_mask=mask)[\"hidden_states\"])\n",
        "\n",
        "        concatenate_pooling = torch.cat(\n",
        "            (all_hidden_states[-1], all_hidden_states[-2], all_hidden_states[-3], all_hidden_states[-4]),-1\n",
        "        )\n",
        "\n",
        "        concatenate_pooling = concatenate_pooling[:, 0]\n",
        "\n",
        "        output_dropout = self.dropout(concatenate_pooling)\n",
        "        \n",
        "        output = self.linear(output_dropout)\n",
        "        return output\n",
        "\n",
        "    # def forward(self, ids, mask):\n",
        "    #     \"\"\"Use pooler output\"\"\"\n",
        "    #     output_1 = self.model(ids, attention_mask=mask)[\"pooler_output\"]\n",
        "    #     output_dropout = self.dropout(output_1)\n",
        "    #     output = self.linear(output_dropout)\n",
        "    #     return output \n",
        "\n",
        "\n",
        "def get_model():\n",
        "  model = vulnerabilityClassifier()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDhVYLaavpHG"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''Takes a time in seconds and returns a string hh:mm:ss'''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj_e5uiGvsat"
      },
      "outputs": [],
      "source": [
        "def tokenize_truncate(tokenizer, text_samples, max_length):\n",
        "    full_input_ids = []\n",
        "\n",
        "    # For each training example...\n",
        "    for text in text_samples:\n",
        "        # Tokenize the sample.\n",
        "        input_ids = tokenizer.encode(text=text,              # Text to encode.\n",
        "                                    add_special_tokens=True, # Do add specials.\n",
        "                                    max_length=max_length,      # Do Truncate!\n",
        "                                    truncation=True,         # Do Truncate!\n",
        "                                    padding=False)           # DO NOT pad.\n",
        "                                    \n",
        "        # Add the tokenized result to our list.\n",
        "        full_input_ids.append(input_ids)\n",
        "        \n",
        "    print('DONE. {:>10,} samples\\n'.format(len(full_input_ids)))\n",
        "    return full_input_ids\n",
        "\n",
        "\n",
        "def build_batches(samples, batch_size):\n",
        "    # List of batches that we'll construct.\n",
        "    batch_ordered_text = []\n",
        "    batch_ordered_labels = []\n",
        "\n",
        "    print('Creating batches of size {:}...'.format(batch_size))\n",
        "\n",
        "    # Loop over all of the input samples...    \n",
        "    while len(samples) > 0:\n",
        "        # `to_take` is our actual batch size. It will be `batch_size` until \n",
        "        # we get to the last batch, which may be smaller. \n",
        "        to_take = min(batch_size, len(samples))\n",
        "\n",
        "        # Pick a random index in the list of remaining samples to start\n",
        "        # our batch at.\n",
        "        select = random.randint(0, len(samples) - to_take)\n",
        "\n",
        "        # Select a contiguous batch of samples starting at `select`.\n",
        "        batch = samples[select:(select + to_take)]\n",
        "\n",
        "        #print(\"Batch length:\", len(batch))\n",
        "\n",
        "        # Each sample is a tuple--split them apart to create a separate list of \n",
        "        # sequences and a list of labels for this batch.\n",
        "        batch_ordered_text.append([s[0] for s in batch])\n",
        "        batch_ordered_labels.append([s[1] for s in batch])\n",
        "\n",
        "        # Remove these samples from the list.\n",
        "        del samples[select:select + to_take]\n",
        "\n",
        "    print('\\t  DONE - Selected {:,} batches.\\n'.format(len(batch_ordered_text)))\n",
        "    return batch_ordered_text, batch_ordered_labels\n",
        "\n",
        "\n",
        "def add_padding_per_batch(tokenizer, batch_ordered_text, batch_ordered_labels):\n",
        "    print('Padding out sequences within each batch...')\n",
        "\n",
        "    final_input_ids = []\n",
        "    final_attention_masks = []\n",
        "    final_labels = []\n",
        "\n",
        "    # For each batch...\n",
        "    for (batch_inputs, batch_labels) in zip(batch_ordered_text, batch_ordered_labels):\n",
        "\n",
        "        # New version of the batch, this time with padded sequences and now with\n",
        "        # attention masks defined.\n",
        "        batch_padded_inputs = []\n",
        "        batch_attn_masks = []\n",
        "        \n",
        "        # First, find the longest sample in the batch. \n",
        "        # Note that the sequences do currently include the special tokens!\n",
        "        max_size = max([len(sen) for sen in batch_inputs])\n",
        "\n",
        "        # For each input in this batch...\n",
        "        for sen in batch_inputs:\n",
        "            \n",
        "            # How many pad tokens do we need to add?\n",
        "            num_pads = max_size - len(sen)\n",
        "\n",
        "            # Add `num_pads` padding tokens to the end of the sequence.\n",
        "            padded_input = sen + [tokenizer.pad_token_id]*num_pads\n",
        "\n",
        "            # Define the attention mask--it's just a `1` for every real token\n",
        "            # and a `0` for every padding token.\n",
        "            attn_mask = [1] * len(sen) + [0] * num_pads\n",
        "\n",
        "            # Add the padded results to the batch.\n",
        "            batch_padded_inputs.append(padded_input)\n",
        "            batch_attn_masks.append(attn_mask)\n",
        "\n",
        "        # Our batch has been padded, so we need to save this updated batch.\n",
        "        # We also need the inputs to be PyTorch tensors, so we'll do that here.\n",
        "        # Todo - Michael's code specified \"dtype=torch.long\"\n",
        "        final_input_ids.append(torch.tensor(batch_padded_inputs))\n",
        "        final_attention_masks.append(torch.tensor(batch_attn_masks))\n",
        "        final_labels.append(torch.tensor(np.array(batch_labels))) # if there's problems, remove np.array()\n",
        "\n",
        "    print('\\t DONE. Returning final smart-batched data.')\n",
        "    # Return the smart-batched dataset!\n",
        "    return (final_input_ids, final_attention_masks, final_labels)\n",
        "\n",
        "\n",
        "def smart_batching(tokenizer, max_length, text_samples, labels, batch_size):\n",
        "    # Tokenize and truncate text_samples; no padding\n",
        "    full_input_ids = tokenize_truncate(tokenizer, text_samples, max_length)\n",
        "\n",
        "    # Sort the two lists together by the length of the input sequence.\n",
        "    samples = sorted(zip(full_input_ids, labels), key=lambda x: len(x[0]))\n",
        "\n",
        "    # Build batches of contiguous data, starting at random points in samples\n",
        "    batch_size = batch_size\n",
        "    batch_ordered_text, batch_ordered_labels = build_batches(samples, batch_size)\n",
        "   \n",
        "    # Add padding accordingly to batch size\n",
        "    final_input_ids, final_attention_masks, final_labels = add_padding_per_batch(tokenizer, batch_ordered_text, batch_ordered_labels)\n",
        "\n",
        "    return final_input_ids, final_attention_masks, final_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80LzTR_RvvAY",
        "outputId": "b68dc5a8-d8af-4019-c896-5ad13f92fd4e"
      },
      "outputs": [],
      "source": [
        "train_input_ids, train_attn_masks, train_labels = smart_batching(tokenizer, 512, train_dataset['Code'], train_dataset['one-hot'], BATCH_SIZE) \n",
        "# test_input_ids, test_attn_masks, test_labels = smart_batching(tokenizer, 512, test_dataset['Code'], test_dataset['one-hot'], BATCH_SIZE)\n",
        "val_input_ids, val_attn_masks, val_labels = smart_batching(tokenizer, 512, val_dataset['Code'], val_dataset['one-hot'], BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aFm_Lzvvw1b"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model):\n",
        "    opt = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 5e-5,                   \n",
        "                  eps = 1e-8                    \n",
        "                )\n",
        "\n",
        "    return opt\n",
        "\n",
        "def get_scheduler(optimizer, num_train_steps):\n",
        "    sch = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
        "    return sch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCQLSmsxypBK"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, labels):\n",
        "    if labels is None:\n",
        "        return None\n",
        "    return nn.BCEWithLogitsLoss()(outputs, labels.float())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAx8QtZFyvM6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def getAccuracy(preds, labels):\n",
        "    prob_preds = torch.stack(preds)\n",
        "    prob_preds = prob_preds.cpu().detach().numpy()\n",
        "    flabels = torch.stack(labels)\n",
        "    flabels = flabels.cpu().detach().numpy()\n",
        "\n",
        "    label_predictions = np.zeros((len(preds), 23))\n",
        "    label_predictions = prob_preds >= 0.5 \n",
        "    label_predictions = label_predictions.astype(int)\n",
        "\n",
        "    # accuracy_score from sklearn calculates subset accuracy \n",
        "    return accuracy_score(flabels, label_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUUumCy6yxi2"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train_fn(train_input_ids, train_attn_masks, train_labels, model, optimizer,scheduler):\n",
        "    print(\"Starting training... \")\n",
        "\n",
        "    update_interval = 500\n",
        "    t0 = time.time()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    final_targets = []\n",
        "    final_outputs = []\n",
        "    \n",
        "    # for each batch\n",
        "    for step in range(0, len(train_input_ids)): \n",
        "        # Progress update every, e.g., 100 batches.\n",
        "        if step % update_interval == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Calculate the time remaining based on our progress.\n",
        "            steps_per_sec = (time.time() - t0) / step\n",
        "            remaining_sec = steps_per_sec * (len(train_input_ids) - step)\n",
        "            remaining = format_time(remaining_sec)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>7,}  of  {:>7,}.    Elapsed: {:}.  Remaining: {:}'.format(step, len(train_input_ids), elapsed, remaining))\n",
        "\n",
        "        ids = train_input_ids[step].to('cuda', dtype = torch.long)\n",
        "        mask = train_attn_masks[step].to('cuda', dtype = torch.long)\n",
        "        targets = train_labels[step].to('cuda', dtype = torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(ids=ids, mask=mask)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        final_targets.extend(targets)\n",
        "        final_outputs.extend(torch.sigmoid(outputs))\n",
        "        \n",
        "        \n",
        "    return train_loss, final_outputs, final_targets\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9WUrYKTyzc0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def eval_fn(test_input_ids, test_attn_masks, test_labels, model):\n",
        "    print('\\nStarting evaluation... ')\n",
        "    \n",
        "    update_interval = 100\n",
        "    t0 = time.time()\n",
        "\n",
        "    eval_loss = 0.0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    final_targets = []\n",
        "    final_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "       for step in range(0, len(test_input_ids)): \n",
        "          if step % update_interval == 0 and not step == 0:\n",
        "              # Calculate elapsed time in minutes.\n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "              # Calculate the time remaining based on our progress.\n",
        "              steps_per_sec = (time.time() - t0) / step\n",
        "              remaining_sec = steps_per_sec * (len(test_input_ids) - step)\n",
        "              remaining = format_time(remaining_sec)\n",
        "              # Report progress.\n",
        "              print('  Batch {:>7,}  of  {:>7,}.    Elapsed: {:}.  Remaining: {:}'.format(step, len(test_input_ids), elapsed, remaining))\n",
        "\n",
        "          ids = test_input_ids[step].to('cuda', dtype = torch.long)\n",
        "          mask = test_attn_masks[step].to('cuda', dtype = torch.long)\n",
        "          targets = test_labels[step].to('cuda', dtype = torch.float)\n",
        "\n",
        "          outputs = model(ids=ids, mask=mask)\n",
        "\n",
        "          loss = loss_fn(outputs, targets)\n",
        "\n",
        "          eval_loss += loss.item()\n",
        "          final_targets.extend(targets)\n",
        "          final_outputs.extend(torch.sigmoid(outputs))\n",
        " \n",
        "    return eval_loss, final_outputs, final_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMzAsr7H7NRp",
        "outputId": "c597ad46-aa1c-4c61-ce4d-692de986928c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O9u4GPdrDbw"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(epoch, optimizer, scheduler, model, train_loss, test_loss):\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'test_loss': test_loss\n",
        "            }, \"/content/drive/MyDrive/path/in/drive/model.bin\")\n",
        "  \n",
        "  print(\"Saved hs_checkpoint_\" + str(epoch) + \".bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "95828cf2a785426a83615b0ba8e2f5a6",
            "b612921d5927415a814eea540a6af4ad",
            "bccb8f7226da47ffa267348153b1a45b",
            "6963a991fe16414dba6b1c6947dd72e3",
            "c78f68fecde04b449780c25253a79cdd",
            "03a40362ceab47b59c31aa65fb5c04dc",
            "08ff0ceaf61445469484a6ae91d0acd6",
            "44e8c19572184c2c8ea5eeb8c63d3015",
            "af92260190804eae99c79155f96d7a3f",
            "d20da720b00a44678f717650ab8a7a17",
            "03858f93748147518ce162221693cbdf",
            "587e6701c6444b44812720717c25e4a2",
            "36cfa23ed2114971ace2732ff2dd0bea",
            "5ad843ed45284ee493c4ee2c6bbaf9cc",
            "75ad03640f8e44078aa2bb300abcf18f",
            "235e312bc04245e4b8e12e2168cd9069",
            "26e58827e3b740ca987c0edd96c8ca4a",
            "a4f0f47c6ecc4a0c882e1cc76e755c92",
            "a317e7ab49f945fe96f9b024ef6f2d9d",
            "5bd530ff1847425082874a95a1379808",
            "4a6449b708e84033b3c729d76dd84deb",
            "464ee50ec1494ffca5cc6bc94b3bb770"
          ]
        },
        "id": "EHTcPGt-Iz7m",
        "outputId": "5d7d7c60-9a46-4c6a-b3ff-b8ed64ea2109"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "n_train_steps = len(train_input_ids) * EPOCHS\n",
        "\n",
        "model = get_model()\n",
        "model.to('cuda')\n",
        "\n",
        "optimizer = get_optimizer(model)\n",
        "scheduler = get_scheduler(optimizer, n_train_steps)\n",
        "\n",
        "# Load checkpoint from a previous model\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/path/in/drive/model.bin')\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "# best_eval_loss = checkpoint['test_loss']\n",
        "# epoch = checkpoint['epoch'] + 1\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmJ8fceKy153",
        "outputId": "d006b354-61fe-402f-83bb-2273c872e13e"
      },
      "outputs": [],
      "source": [
        "while epoch < EPOCHS:\n",
        "    print(\"\\t\\t epoch: \", epoch)\n",
        "\n",
        "    if epoch > 0: # This is not cross-validation! \n",
        "      train_input_ids, train_attn_masks, train_labels = smart_batching(tokenizer, 512, train_dataset['Code'], train_dataset['one-hot'], 12) \n",
        "      val_input_ids, val_attn_masks, val_labels = smart_batching(tokenizer, 512, val_dataset['Code'], val_dataset['one-hot'], 12)\n",
        "\n",
        "    train_loss, train_preds, train_true_labels = train_fn(train_input_ids, train_attn_masks, train_labels, model, optimizer, scheduler)\n",
        "    eval_loss, eval_preds, eval_true_labels = eval_fn(val_input_ids, val_attn_masks, val_labels, model)\n",
        "\n",
        "    avg_train_loss, avg_val_loss = train_loss / len(train_input_ids), eval_loss / len(val_input_ids)\n",
        "    train_acc = getAccuracy(train_preds, train_true_labels) \n",
        "    eval_acc = getAccuracy(eval_preds, eval_true_labels)\n",
        "\n",
        "    train_info = \"Avg Train loss (loss/batch): \" + str(avg_train_loss) +  \"\\t Train accuracy: \" + str(train_acc) + \"\\n\"\n",
        "    val_info = \"Avg Valid loss (loss/batch): \" + str(avg_val_loss) + \"\\t Validation accuracy: \" + str(eval_acc) + \"\\n\\n\"\n",
        "\n",
        "    f = open(\"/content/loss.txt\", \"a\")\n",
        "    f.write(train_info)\n",
        "    f.write(val_info)\n",
        "    print(train_info)\n",
        "    print(val_info)\n",
        "    f.close()\n",
        "\n",
        "    scheduler.step()\n",
        "    save_checkpoint(epoch, optimizer, scheduler, model, train_loss, eval_loss)\n",
        "    epoch = epoch + 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4oGJ7JTMQJa"
      },
      "source": [
        "From this cell onwards, we just test the final checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "UkfQeii1ovk9",
        "outputId": "3cff32ff-287c-43a7-b576-d0b1985de7a3"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model = get_model()\n",
        "model.to('cuda')\n",
        "\n",
        "# Load best model iteration for testing\n",
        "checkpoint = torch.load('/content/drive/MyDrive/path/in/drive/model.bin')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "best_eval_loss = checkpoint['test_loss']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZkH4K9bDZL1",
        "outputId": "abc57f11-061b-42cb-af6d-d55a382fe0d3"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "test_dataset = pd.read_csv(\"/content/ds.csv\")\n",
        "test_dataset['one-hot'] = test_dataset['one-hot'].apply(literal_eval)\n",
        "\n",
        "test_input_ids, test_attn_masks, test_labels = smart_batching(tokenizer, 512, test_dataset['code'], test_dataset['one-hot'], BATCH_SIZE)\n",
        "\n",
        "test_loss, test_preds, test_true_labels = eval_fn(test_input_ids, test_attn_masks, test_labels, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGJHrsqAD6Bn",
        "outputId": "a782a6d1-ec40-4877-8616-015a39b16630"
      },
      "outputs": [],
      "source": [
        "test_accuracy = getAccuracy(test_preds, test_true_labels)\n",
        "\n",
        "#subset accuracy\n",
        "print(test_accuracy) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmdkE_okeusU",
        "outputId": "dd6ca164-7593-4b6d-b154-9862320520bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "prob_preds = torch.stack(test_preds)\n",
        "prob_preds = prob_preds.cpu().detach().numpy()\n",
        "\n",
        "label_predictions = (prob_preds > 0.5).astype(int) \n",
        "\n",
        "flabels = torch.stack(test_true_labels)\n",
        "flabels = flabels.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = multilabel_confusion_matrix(flabels, label_predictions) #use this to get FP, FN, TP, TN to calculate accuracy\n",
        "\n",
        "cf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfsr2gwcZece",
        "outputId": "61b15736-2dee-4075-d0be-376d93804f35"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cr = classification_report(flabels, label_predictions)\n",
        "print(cr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03858f93748147518ce162221693cbdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03a40362ceab47b59c31aa65fb5c04dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ff0ceaf61445469484a6ae91d0acd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "235e312bc04245e4b8e12e2168cd9069": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e58827e3b740ca987c0edd96c8ca4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36cfa23ed2114971ace2732ff2dd0bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e58827e3b740ca987c0edd96c8ca4a",
            "placeholder": "​",
            "style": "IPY_MODEL_a4f0f47c6ecc4a0c882e1cc76e755c92",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "44e8c19572184c2c8ea5eeb8c63d3015": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "464ee50ec1494ffca5cc6bc94b3bb770": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a6449b708e84033b3c729d76dd84deb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587e6701c6444b44812720717c25e4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36cfa23ed2114971ace2732ff2dd0bea",
              "IPY_MODEL_5ad843ed45284ee493c4ee2c6bbaf9cc",
              "IPY_MODEL_75ad03640f8e44078aa2bb300abcf18f"
            ],
            "layout": "IPY_MODEL_235e312bc04245e4b8e12e2168cd9069"
          }
        },
        "5ad843ed45284ee493c4ee2c6bbaf9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a317e7ab49f945fe96f9b024ef6f2d9d",
            "max": 438147282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bd530ff1847425082874a95a1379808",
            "value": 438147282
          }
        },
        "5bd530ff1847425082874a95a1379808": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6963a991fe16414dba6b1c6947dd72e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d20da720b00a44678f717650ab8a7a17",
            "placeholder": "​",
            "style": "IPY_MODEL_03858f93748147518ce162221693cbdf",
            "value": " 593/593 [00:00&lt;00:00, 6.17kB/s]"
          }
        },
        "75ad03640f8e44078aa2bb300abcf18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a6449b708e84033b3c729d76dd84deb",
            "placeholder": "​",
            "style": "IPY_MODEL_464ee50ec1494ffca5cc6bc94b3bb770",
            "value": " 418M/418M [00:25&lt;00:00, 18.3MB/s]"
          }
        },
        "95828cf2a785426a83615b0ba8e2f5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b612921d5927415a814eea540a6af4ad",
              "IPY_MODEL_bccb8f7226da47ffa267348153b1a45b",
              "IPY_MODEL_6963a991fe16414dba6b1c6947dd72e3"
            ],
            "layout": "IPY_MODEL_c78f68fecde04b449780c25253a79cdd"
          }
        },
        "a317e7ab49f945fe96f9b024ef6f2d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f0f47c6ecc4a0c882e1cc76e755c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af92260190804eae99c79155f96d7a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b612921d5927415a814eea540a6af4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03a40362ceab47b59c31aa65fb5c04dc",
            "placeholder": "​",
            "style": "IPY_MODEL_08ff0ceaf61445469484a6ae91d0acd6",
            "value": "Downloading config.json: 100%"
          }
        },
        "bccb8f7226da47ffa267348153b1a45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44e8c19572184c2c8ea5eeb8c63d3015",
            "max": 593,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af92260190804eae99c79155f96d7a3f",
            "value": 593
          }
        },
        "c78f68fecde04b449780c25253a79cdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20da720b00a44678f717650ab8a7a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
